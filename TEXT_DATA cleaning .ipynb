{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING STEPS FOR NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OzAkOXfkft4x"
   },
   "outputs": [],
   "source": [
    "# Required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "sVfXJMbMgQmJ",
    "outputId": "2861f17d-061d-4424-fed6-68d1f3fea531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 Im an alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1995</td>\n",
       "      <td>@flcnhvy True, it sounds so surreal, but the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>@PPathole Make sure to read ur terms &amp;amp; con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>@TeslaGong @PPathole Samwise Gamgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>@PPathole Altho Dumb and Dumber is &lt;U+0001F525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Progress update August 28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text\n",
       "0              1                             @kunalb11 Im an alien\n",
       "1              2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
       "2              3                @joerogan @Spotify Great interview!\n",
       "3              4                    @gtera27 Doge is underestimated\n",
       "4              5  @teslacn Congratulations Tesla China for amazi...\n",
       "...          ...                                                ...\n",
       "1994        1995  @flcnhvy True, it sounds so surreal, but the n...\n",
       "1995        1996  @PPathole Make sure to read ur terms &amp; con...\n",
       "1996        1997                @TeslaGong @PPathole Samwise Gamgee\n",
       "1997        1998  @PPathole Altho Dumb and Dumber is <U+0001F525...\n",
       "1998        1999                          Progress update August 28\n",
       "\n",
       "[1999 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the text data\n",
    "elon = pd.read_csv('E:/DATA SCI ASSI/text mining/Elon_musk.csv', encoding='unicode_escape')\n",
    "elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                kunalb11 Im an alien\n",
       "1    IDAACarmack Ray tracing on Cyberpunk with HDR ...\n",
       "2                     joerogan Spotify Great interview\n",
       "3                       gtera27 Doge is underestimated\n",
       "4    teslacn Congratulations Tesla China for amazin...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean data ,Removing the punctuations\n",
    "import string\n",
    "\n",
    "def pun_removal(messy_str):\n",
    "  clean_list=[char for char in messy_str if char not in string.punctuation]\n",
    "  clean_str=''.join(clean_list)\n",
    "  return clean_str\n",
    "\n",
    "elon['Text']=elon['Text'].apply(pun_removal)\n",
    "#check Top 5_Reviews\n",
    "elon['Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  kunalb Im an alien\n",
       "1    IDAACarmack Ray tracing on Cyberpunk with HDR ...\n",
       "2                     joerogan Spotify Great interview\n",
       "3                         gtera Doge is underestimated\n",
       "4    teslacn Congratulations Tesla China for amazin...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# leats reamoving numbers\n",
    "\n",
    "def drop_num(list_text):\n",
    "    list_text_new=[]\n",
    "    for i in list_text:\n",
    "        if not re.search('\\d',i):\n",
    "            list_text_new.append(i)\n",
    "    return ''.join(list_text_new)\n",
    "\n",
    "elon['Text']=elon['Text'].apply(drop_num)\n",
    "#check Top 5_Reviews\n",
    "elon['Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      kunalbImanalien\n",
       "1    IDAACarmackRaytracingonCyberpunkwithHDRisnextl...\n",
       "2                        joeroganSpotifyGreatinterview\n",
       "3                            gteraDogeisunderestimated\n",
       "4    teslacnCongratulationsTeslaChinaforamazingexec...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the special characters\n",
    "def remove_special_char(tx):\n",
    "  pat=r'[^a-zA-z0-9]'\n",
    "  return re.sub(pat,'',tx)\n",
    "elon['Text']=elon['Text'].apply(lambda x:remove_special_char(x))\n",
    "\n",
    "#check Top 5_Reviews\n",
    "elon['Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      kunalbImanalien\n",
       "1    IDAACarmackRaytracingonCyberpunkwithHDRisnextl...\n",
       "2                        joeroganSpotifyGreatinterview\n",
       "3                            gteraDogeisunderestimated\n",
       "4    teslacnCongratulationsTeslaChinaforamazingexec...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing the Accented characters\n",
    "import unicodedata\n",
    "\n",
    "def remove_accented_char(tx):\n",
    "  new_text=unicodedata.normalize('NFKD',tx).encode('ascii','ignore').decode('utf-8','ignore')\n",
    "  return new_text\n",
    "elon['Text']=elon['Text'].apply(lambda x:remove_accented_char(x))\n",
    "\n",
    "#check Top 5_Reviews\n",
    "elon['Text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "elon['Text'] = elon['Text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "r4hDCUzHoQEq"
   },
   "outputs": [],
   "source": [
    "# Calculate count of wards , characters count in review clm\n",
    "# used 'len' fuction for char_count= length\n",
    "elon[\"length\"]=elon['Text'].apply(len)\n",
    "# Words count\n",
    "elon['Words_count']=elon['Text'].apply(lambda x:len(x.split()))\n",
    "# Word Density\n",
    "elon['Word_Density']=elon['length']/(elon['Words_count']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "j7-mmlnkshXm",
    "outputId": "d6277bdc-67a2-443d-a6bb-42a9fccc586c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>Words_count</th>\n",
       "      <th>Word_Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.904952</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>30.452476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.770994</td>\n",
       "      <td>0.022366</td>\n",
       "      <td>17.385497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>59.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length  Words_count  Word_Density\n",
       "count  1999.000000  1999.000000   1999.000000\n",
       "mean     60.904952     0.999500     30.452476\n",
       "std      34.770994     0.022366     17.385497\n",
       "min       0.000000     0.000000      0.000000\n",
       "25%      30.000000     1.000000     15.000000\n",
       "50%      53.000000     1.000000     26.500000\n",
       "75%     101.000000     1.000000     50.500000\n",
       "max     119.000000     1.000000     59.500000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon[['length','Words_count','Word_Density']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zXVpLDu8lS5M"
   },
   "outputs": [],
   "source": [
    "# LETS CREAT A PART OF SPEECH DICTIONARY\n",
    "POS_DIC={\n",
    "    'noun':['NN','NNS','NNP','NNPS'],             # NN stands for singular noun\n",
    "    'pron':['PRP','PRP$','WP','WP$'],             # NNS stands for plural noun\n",
    "    'verb':['VB','VBD','VBG','VBN','VBP','VBZ'],  # NNP stands for singular proper noun\n",
    "    'adj':['JJ','JJR','JJS'],                     # NNps stands for plural proper noun\n",
    "    'adv':['RB','RBR','RBS','WRB']\n",
    "}\n",
    "#Create function to check and get part of speech tag count of a wards in given sentence\n",
    "def pos_check(x,flag):\n",
    "    cnt=0\n",
    "    try:\n",
    "        wiki=TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo= list(tup)[1]\n",
    "            if ppo in POS_DIC[flag]:\n",
    "                cnt += 1\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rK-PnqlMl0gl",
    "outputId": "11e9a391-e9b2-4c15-83e3-747436811ecd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 11001] getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "  \n",
    "#calculate the count of nouns in the text\n",
    "elon['nouns_cnt']=elon['Text'].apply(lambda x:pos_check(x,'noun'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "um8b2nLjmQ45",
    "outputId": "17b1c816-11af-4d91-8cc2-9d80e114ab96"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>length</th>\n",
       "      <th>Words_count</th>\n",
       "      <th>Word_Density</th>\n",
       "      <th>nouns_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>kunalbImanalien</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>IDAACarmackRaytracingonCyberpunkwithHDRisnextl...</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>joeroganSpotifyGreatinterview</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gteraDogeisunderestimated</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>teslacnCongratulationsTeslaChinaforamazingexec...</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1995</td>\n",
       "      <td>flcnhvyTrueitsoundssosurrealbutthenegativeprop...</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>PPatholeMakesuretoreadurtermsampconditionsbefo...</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>TeslaGongPPatholeSamwiseGamgee</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>PPatholeAlthoDumbandDumberisUFUF</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>ProgressupdateAugust</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text  length  \\\n",
       "0              1                                    kunalbImanalien      15   \n",
       "1              2  IDAACarmackRaytracingonCyberpunkwithHDRisnextl...      64   \n",
       "2              3                      joeroganSpotifyGreatinterview      29   \n",
       "3              4                          gteraDogeisunderestimated      25   \n",
       "4              5  teslacnCongratulationsTeslaChinaforamazingexec...      84   \n",
       "...          ...                                                ...     ...   \n",
       "1994        1995  flcnhvyTrueitsoundssosurrealbutthenegativeprop...     110   \n",
       "1995        1996  PPatholeMakesuretoreadurtermsampconditionsbefo...      62   \n",
       "1996        1997                     TeslaGongPPatholeSamwiseGamgee      30   \n",
       "1997        1998                   PPatholeAlthoDumbandDumberisUFUF      32   \n",
       "1998        1999                               ProgressupdateAugust      20   \n",
       "\n",
       "      Words_count  Word_Density  nouns_cnt  \n",
       "0               1           7.5          0  \n",
       "1               1          32.0          0  \n",
       "2               1          14.5          0  \n",
       "3               1          12.5          0  \n",
       "4               1          42.0          0  \n",
       "...           ...           ...        ...  \n",
       "1994            1          55.0          0  \n",
       "1995            1          31.0          0  \n",
       "1996            1          15.0          0  \n",
       "1997            1          16.0          0  \n",
       "1998            1          10.0          0  \n",
       "\n",
       "[1999 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qh3nWf3_3kls",
    "outputId": "2b3d56b3-0757-4a1b-a36a-77f6e5b46243"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      kunalbImanalien\n",
       "1    IDAACarmackRaytracingonCyberpunkwithHDRisnextl...\n",
       "2                        joeroganSpotifyGreatinterview\n",
       "3                            gteraDogeisunderestimated\n",
       "4    teslacnCongratulationsTeslaChinaforamazingexec...\n",
       "5                  HappyNewYearoftheOxhttpstcoWFKMYuoj\n",
       "6    FrodowastheunderdogeAllthoughthewouldfailHimse...\n",
       "7                    OwenSparksflcnhvyanonyxHahathanks\n",
       "8    flcnhvyanonyxIndeedTweetsdefinitelydonotrepres...\n",
       "9            Themostentertainingoutcomeisthemostlikely\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leats visualize the top 10 revivews after reamoving numbers and punctuations\n",
    "elon['Text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNw9uclpAQOZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
